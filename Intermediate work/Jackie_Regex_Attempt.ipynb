{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Jackie's Regex Attempt \n",
    "I used Sagar's file, \"SagarsCleaningAttempt.csv\" for my starting point. I created a column 'Test_6' that shows changes from previous attempts.\n",
    "The code below cleans the following:\n",
    "\n",
    "**remove leading/trailing parentheses plus words inside, ex: \"some stuff) food\" or \"food (some stuff\"\n",
    "\n",
    "**remove complete parentheses plus words inside, ex: \"(some stuff) food\" or \"food (some stuff) or \"food (some stuff) food\"\n",
    "\n",
    "**remove dashes only at beginning/end of sentence, ex: \" - some food\" or \"some food -\"\n",
    "\n",
    "**remove unicode characters\n",
    "\n",
    "**remove the word 'of' and words before it, ex: \"dash of salt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achiote (annatto) seeds\n",
      "365\n",
      "large crispin (matsu) apple or a golden delicious apple\n",
      "390\n",
      "shelled fresh fava beans (from about pods) or frozen fava beans\n",
      "408\n",
      "eggplants pcs (cut into small pieces pcs about slices) than taking the inside out\n",
      "1116\n",
      "plus (or more) vegetable broth\n",
      "1839\n",
      "lb. (about medium) golden beets\n",
      "1890\n",
      "x x pan or individual dessert (my dessert cups pictured above hold capacity). if you have a slightly larger or smaller pan\n",
      "1927\n",
      "of collards (about pounds) or two bags chopped collards\n",
      "2091\n",
      "dashi (see note above) or vegetable broth\n",
      "2138\n",
      "ancho (or regular) chili powder\n",
      "2198\n",
      "scotch bonnet (deseeded) - optional if you want more heat\n",
      "2467\n",
      "jars (each oz.) williams-sonoma roasted\n",
      "3549\n",
      "bottles (each ml) cabernet sauvignon\n",
      "3619\n",
      "1-quart wide-mouthed jar (with a lid) in glass or clear plastic\n",
      "3798\n",
      "or (each oz.) fire-roasted\n",
      "3805\n",
      "shelled fresh fava beans (from about pods) or frozen fava beans\n",
      "4156\n",
      "sheets (about lb.) phyllo dough\n",
      "4215\n",
      "english (hothouse) cucumbers\n",
      "4416\n",
      "english (hothouse) cucumbers\n",
      "4521\n",
      "bags (each lb.) ice\n",
      "4639\n",
      "about toasted crostini (see note above) or large crackers\n",
      "5292\n",
      "english (hothouse) cucumbers\n",
      "5486\n",
      "tsp. powdered asafetida (see note) or\n",
      "5495\n",
      "totopos (see related recipe at left) or small crackers for serving\n",
      "5581\n",
      "dinosaur (lacinato) kale\n",
      "5672\n",
      "tbs. (about packets) unflavored gelatin\n",
      "6010\n",
      "gremolata (see headnote) for serving\n",
      "6629\n",
      "pieces (each by inches) sushi nori\n",
      "6960\n",
      "english (hothouse) cucumbers\n",
      "7799\n",
      "alchermes (see note) or framboise\n",
      "8035\n",
      "bags (each oz.) caramels\n",
      "8091\n",
      "homemade (see related recipe at left) or\n",
      "8230\n",
      "dandelion leaves (bite-size pieces) or\n",
      "8292\n",
      "jello (or store brand gelatin dessert) in different colors\n",
      "8970\n",
      "piece (about pounds) smoked\n",
      "9027\n",
      "savoiardi (dried ladyfingers) crumbs\n",
      "9252\n",
      "naan (indian flatbread) and/or cooked\n",
      "9536\n",
      "roman (large globe) artichokes\n",
      "9837\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from string import digits\n",
    "\n",
    "# Reading csv file:\n",
    "#regex_df = pd.read_csv('./SagarsCleaningAttempt.csv')    #, delimiter=',', encoding=\"utf-8\")\n",
    "regex_df = pd.read_csv('./80000_90000_Clean.csv') \n",
    "\n",
    "small_df = regex_df.copy()\n",
    "#small_df = small_df[0:500]\n",
    "\n",
    "#Add a new column, Regex, and fill it with everything from After column\n",
    "small_df['Regex'] = small_df['after']\n",
    "\n",
    "small_df['Regex'] = small_df['Regex'].astype(str)\n",
    "\n",
    "#small_df.drop(small_df.index[[2295]], inplace=True)\n",
    "#small_df.drop(small_df.index[[7764]], inplace=True)\n",
    "#small_df.drop(small_df.index[[7765]], inplace=True)\n",
    "#small_df.drop(small_df.index[[7766]], inplace=True)\n",
    "\n",
    "#First, get rid of annoying unicode characters\n",
    "for i, row in small_df.iterrows():\n",
    "    #make an array of ingredients for the current row\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        s = ingr\n",
    "        s = s.decode('unicode_escape').encode('ascii','ignore') # remove annoying characters like Â½\n",
    "        s = s.strip() # remove any leading/trailing whitespace\n",
    "        #print(s)\n",
    "        arr[j] = s\n",
    "        \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr)) # put back into dataframe\n",
    "\n",
    "#delete the '-' sign at the beginning of the string\n",
    "pattern = r'(^\\s*\\-{1,})'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match1\")\n",
    "            dash, rest = re.split(r'^\\-', ingr)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "        \n",
    "#delete the '-' sign at the end of the string\n",
    "pattern = r'(\\s*\\-{1,})$'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match2\")\n",
    "            rest, dash = re.split(r'\\-', ingr, 1)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "        \n",
    "        \n",
    "#delete parentheses (at beginning) with any words, nums, or dashes in them: \"(something) blah blah\"\n",
    "pattern = r'^(\\()[ \\w\\-\\'\\!\\;\\.\\\"\\&\\]\\[\\/0-9]*(\\))'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match5\")\n",
    "            before_p, parenth, rest = re.split(r'[(\\()(\\))]', ingr, 2)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "\n",
    "#delete parentheses (at end) with any words, nums, or dashes in them: \"blah blah (something)\"\n",
    "pattern = r'(\\()[ \\w\\-\\'\\!\\;\\.\\\"\\&\\]\\[\\/0-9]*(\\))$'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match6\")\n",
    "            rest, before_p, after_p, space = re.split(r'(\\()[ \\w\\-\\'\\!\\;\\.\\\"\\&\\]\\[\\/0-9]*(\\))$', ingr)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "        \n",
    "#delete one open parenthesis (at beginning) with this case: \"something) blah blah\" \n",
    "pattern = r'^[ \\w\\-\\'\\!\\;\\.\\\"\\&\\]\\[\\/0-9]*(\\))'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match3\")\n",
    "            #print(ingr)\n",
    "            before_p, parenth, rest = re.split(r'^[ \\w\\-\\'\\!\\;\\.\\\"\\&\\]\\[\\/0-9]*(\\))', ingr)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "\n",
    "#delete one open parenthesis (at end) with this case: \"blah blah (something\"\n",
    "pattern = r'(\\()[ \\w\\-\\'\\!\\;\\.\\\"\\&\\]\\[\\/0-9]*$'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match4\")\n",
    "            rest, parenth, after_p = re.split(r'(\\()', ingr, 1)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "\n",
    "\n",
    "#get rid of extra ')' at the end: \"food stuff extra symbol at end)\n",
    "pattern = r'(\\))$'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match')'\")\n",
    "            rest, parenth, space = re.split(r'(\\))$', ingr)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "\n",
    "\n",
    "#delete parentheses (in the middle) with any words, nums, or dashes in them: \"blah (something) blah\"\n",
    "pattern = r'(\\()[ \\w\\-\\'\\!\\;\\.\\\"\\&\\]\\[\\/0-9]*(\\))'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match7\")\n",
    "            print(ingr)\n",
    "            print(i)\n",
    "            rest1, parenth, rest2 = re.split(r'[(\\()(\\))]', ingr)\n",
    "            new_str = (rest1 + rest2).strip() #remove any leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "        \n",
    "#Get rid of the word 'of' and anything before it: \"an ounce of milk\"\n",
    "pattern = r'\\bof\\b'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(pattern, ingr)):\n",
    "            #print(\"match8\")\n",
    "            #print(ingr)\n",
    "            dash, rest = re.split(r'\\bof\\b', ingr, 1)\n",
    "            new_str = rest.strip() #remove leading/trailing whitespace\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "\n",
    "\n",
    "#Get rid of any stray ';' symbols in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'\\;', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split(';'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#replace '&amp' with just and\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'\\&', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ingr.replace(\"&amp\", \" and \")\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "#remove any stray dashes '-'\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'\\-', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('-'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "            \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr)) \n",
    "            \n",
    "#Get rid of any stray '.' symbols in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'\\.', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('.'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray '/' symbols in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'\\/', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('/'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray '_' symbols in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'\\_', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('_'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'tbsp' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'tbsp', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('tbsp'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'tsp' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'tsp', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('tsp'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "\n",
    "#Get rid of any stray 'lbs' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'lbs', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('lbs'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))    \n",
    "\n",
    "#Get rid of any stray 'lb' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'lb', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('lb'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'oz' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'oz\\s', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('oz'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'kg' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'kg', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('kg'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "\n",
    "#Get rid of any stray g for grams at the beginning of the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'^\\d*g\\s', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('g', 1))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'ml' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'^\\d*\\s*ml\\s', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('ml', 1))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'fl' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'^\\d*\\s*fl\\s', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('fl', 1))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'mm' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'^\\d*\\s*mm\\s', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('mm', 1))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'x' at the beginning of the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'^\\s*x\\s', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('x', 1))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray numbers in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'\\d+', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ingr.translate(None, digits)\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'cups' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'cups', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('cups'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "#Get rid of any stray 'cup' in the ingr\n",
    "for i, row in small_df.iterrows():\n",
    "    arr = row['Regex'].split(\",\")\n",
    "    for j, ingr in enumerate(arr):\n",
    "        if(re.search(r'cup', ingr)):\n",
    "            #print(ingr)\n",
    "            new_str = ' '.join(ingr.split('cup'))\n",
    "            new_str = ' '.join(new_str.split())\n",
    "            #print(new_str)\n",
    "            arr[j] = new_str\n",
    "    \n",
    "    small_df.set_value(i, 'Regex', \",\".join(arr))\n",
    "    \n",
    "\n",
    "#what about words stuck together? like saltsalt\n",
    "    \n",
    "print(\"Done!\")\n",
    "\n",
    "small_df.to_csv('80000_90000_Clean.csv', sep=',', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ')', ' something blah']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "Fitting LDA model ...\n",
      "\n",
      "Topics in LDA model:\n",
      "\n",
      "Topic #0:\n",
      "powder garlic pepper onion black sauce salt water\n",
      "\n",
      "Topic #1:\n",
      "vinegar oil olive pepper red sugar salt black\n",
      "\n",
      "Topic #2:\n",
      "cheese pepper onion eggs butter garlic salt milk\n",
      "\n",
      "Topic #3:\n",
      "eggs flour sugar butter powder salt milk vanilla\n",
      "\n",
      "Topic #4:\n",
      "garlic onion pepper oil olive butter salt sugar\n",
      "\n",
      "Topic #5:\n",
      "sauce garlic pepper onion oil sugar salt butter\n",
      "\n",
      "Topic #6:\n",
      "lemon juice garlic sugar butter pepper salt oil\n",
      "\n",
      "Topic #7:\n",
      "cream butter sugar eggs salt pepper onion milk\n",
      "\n",
      "Topic #8:\n",
      "juice sugar salt butter pepper oil garlic water\n",
      "\n",
      "Topic #9:\n",
      "all purpose flour sugar butter salt vanilla eggs\n",
      "\n",
      "Topic #10:\n",
      "black pepper salt oil olive garlic onion butter\n",
      "\n",
      "Topic #11:\n",
      "olive oil salt pepper butter sugar garlic eggs\n",
      "\n",
      "Topic #12:\n",
      "red pepper onion olive oil garlic tomatoes black\n",
      "\n",
      "Topic #13:\n",
      "water sugar salt flour butter oil pepper onion\n",
      "\n",
      "Topic #14:\n",
      "vanilla sugar milk cream butter eggs salt cheese\n",
      "\n",
      "Topic #15:\n",
      "chicken pepper onion garlic oil butter olive black\n",
      "\n",
      "Topic #16:\n",
      "vegetable oil water salt onion eggs pepper garlic\n",
      "\n",
      "Topic #17:\n",
      "milk butter sugar salt flour eggs pepper onion\n",
      "\n",
      "Topic #18:\n",
      "egg sugar flour butter milk vanilla salt cream\n",
      "\n",
      "Topic #19:\n",
      "tomatoes olive oil garlic pepper onion black salt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "lda_df = pd.read_csv('./Clean_Recipes.csv') \n",
    "\n",
    "lda_small = lda_df.copy()\n",
    "#lda_small = lda_small[0:50]\n",
    "lda_small['Regex'] = lda_small['Regex'].astype(str)\n",
    "\n",
    "dataset = []\n",
    "for i, row in lda_small.iterrows():\n",
    "    dataset.append(row['Regex'])\n",
    "    \n",
    "#print(dataset)\n",
    "    \n",
    "n_features = 2000\n",
    "n_topics = 20\n",
    "n_top_words = 8\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "    \n",
    "\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(stop_words={'english','of','for','the'}, min_df=0.1, max_df=1.0)\n",
    "#tf_vectorizer = CountVectorizer(max_df=1, min_df=0, max_features=n_features, stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(dataset)\n",
    "\n",
    "print(\"Fitting LDA model ...\")\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=100,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.)\n",
    "\n",
    "lda.fit(tf)\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs489]",
   "language": "python",
   "name": "conda-env-cs489-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
